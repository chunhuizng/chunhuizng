### Hi there ðŸ‘‹

I'm **Chunhui Zhang**, a Ph.D. student in Computer Science at Dartmouth ðŸŒ², working with [ðŸŒŸProfessor Soroush Vosoughi](https://www.cs.dartmouth.edu/~soroush/). I also hold an MSCS degree (research-based) from Brandeis University, where I was honored with the GSAS Fellowship, and a Bachelor's degree in CS from Northeastern University, receiving the Outstanding Honor Thesis Award.

---

### ðŸ”­ Research Focus and Key Contributions

My research focuses on advancing the intrinsic properties of deep learning across diverse modalities, with an emphasis on trustworthiness, scalability, and applicability to real-world challenges. Highlights of my work include:

- **Overcoming Multi-step Complexity in Theory-of-Mind Reasoning: A Scalable Bayesian Planner**  
  [Preprint](https://drive.google.com/file/d/1vnAb1dy5_RJcA1vvSPP00u57sBi2hQp9/view?usp=sharing) | [Code](https://anonymous.4open.science/r/scale-bayesian-tom-248B)  
  *Conference:* NAACL 2025 
  *Authors:* Chunhui Zhang, Sean Dae Houlihan, Kwonjoon Lee, Nakul Agarwal, Zhongyu Ouyang, Soroush Vosoughi, Shao-Yuan Lo  

- **Pretrained Image-Text Models are Secretly Video Captioners**  
  [Preprint](https://drive.google.com/file/d/1BDlofqXvD62j9drpLhXnmjZfdwJsnLlH/view?usp=sharing) | [Code](https://anonymous.4open.science/r/ic2vc)
  *Conference:* NAACL 2025 
  *Authors:* {Chunhui Zhang*, Yiren Jian*}, Zhongyu Ouyang, Soroush Vosoughi  

- **Temporal Working Memory: Query-Guided Temporal Segment Refinement for Enhanced Multimodal Understanding**  
  [Preprint](https://drive.google.com/file/d/12aPkYhu2fVS4g8bWNMNkXRcIvZYDJ_rA/view?usp=sharing) | [Code](https://github.com/chunhuizng/amuse)  
  *Conference:* NAACL 2025 
  *Authors:* {Chunhui Zhang*, Xingjian Diao*}, Weiyi Wu, Zhongyu Ouyang, Peijun Qing, Ming Cheng, Soroush Vosoughi, Jiang Gui  

- **Working Memory Identifies Reasoning Limits in Language Models**  
  *Conference:* EMNLP 2024  
  *Authors:* Chunhui Zhang, Yiren Jian, Zhongyu Ouyang, Soroush Vosoughi  

- **Learning Musical Representations for Music Performance Question Answering**  
  *Conference:* Findings of EMNLP 2024  
  *Authors:* Xingjian Diao, Chunhui Zhang, Tingxuan Wu, Ming Cheng, Zhongyu Ouyang, Weiyi Wu, Soroush Vosoughi, Jiang Gui  

---

### ðŸ’¼ Internship Experience

#### **Honda Research Institute USA**  
*Research Intern (Jun. 2024 â€“ Sept. 2024)*  
- **Project:** Multimodal LLM Post-Training  
- Developed a **LLM-powered reasoner** capable of understanding human behaviors in **multimodal environments**, achieving a **4.6% improvement** over state-of-the-art solutions.  
- The paper is under review, and the code has been released.  
- **Host:** [Dr. Shao-Yuan Lo](https://shaoyuanlo.github.io/)  

---

### ðŸŒ± Current Focus

I am currently exploring **Multimodal LLMs** (Language-Vision-Audio), **memory mechanisms**, and **reinforcement learning** to push the boundaries of AGI. My recent work includes training recipes for large-scale models, which ranked **Top-2 on PaperWithCodeâ€™s Video Captioning Leaderboard**, showcasing optimal strategies for resource allocation in post-training.

---

### ðŸ“« Reach Me

- Email: [chunhui.zhang.gr@dartmouth.edu](mailto:chunhui.zhang.gr@dartmouth.edu)  
- LinkedIn: [Chunhui Zhang](https://www.linkedin.com/in/chunhui-zhang-541827161/)  
- GitHub: [chunhuizng](https://github.com/chunhuizng)  
- Google Scholar: [My Publications](https://scholar.google.com.hk/citations?user=im3dmssAAAAJ&hl=en)  

---

### ðŸ’¬ Let's Connect

Feel free to reach out if you're interested in collaboration, career advice, or just a friendly chat about research and life!  
