### Hi there ðŸ‘‹

I'm **Chunhui Zhang**, a Ph.D. candidate in Computer Science at Dartmouth ðŸŒ², working with [ðŸŒŸProfessor Soroush Vosoughi](https://www.cs.dartmouth.edu/~soroush/). I also hold an MSCS degree (research-based) from Brandeis University, where I was honored with the GSAS Fellowship, and a Bachelor's degree in CS from Northeastern University, receiving the Outstanding Honor Thesis Award.

---

### ðŸ”­ Research

My research focuses on advancing the intrinsic properties of deep learning across diverse modalities, with an emphasis on trustworthiness, scalability, and applicability to real-world challenges. Highlights of my work include:

- **Overcoming Multi-step Complexity in Theory-of-Mind Reasoning: A Scalable Bayesian Planner**  
  *Conference:* ICML 2025, **Spotlight (Top 2.59%)**. \
  *Authors:* Chunhui Zhang, Zhongyu Ouyang, Kwonjoon Lee, Nakul Agarwal, Sean Dae Houlihan, {Soroush Vosoughi, Shao-Yuan Lo}

- **Growing Through Experience: Scaling Episodic Grounding in Language Models**  
  *Conference:* ACL 2025, **Oral Presentation (Top 3.24%)**. \
  *Authors:* Chunhui Zhang, Sirui Wang, Zhongyu Ouyang, Xiangchi Yuan, Soroush Vosoughi

- **Pretrained Image-Text Models are Secretly Video Captioners**  
  *Conference:* NAACL 2025 **Oral Presentation (Top 2.88%)**. \
  *Authors:* Chunhui Zhang*, Yiren Jian*, Zhongyu Ouyang, Soroush Vosoughi  

- **Knowing More, Acting Better: Hierarchical Representation for Embodied Decision-Making for PPO Training**  
  *Conference:* Findings of EMNLP 2025 \
  *Authors:* Chunhui Zhang, Zhongyu Ouyang, Xingjian Diao, Zheyuan Liu, Soroush Vosoughi

- **Superficial Self-Improved Reasoners Benefit from Model Merging**  
  *Conference:* EMNLP 2025 \
  *Authors:* Xiangchi Yuan, Chunhui Zhang, Zheyuan Liu, Dachuan Shi, Soroush Vosoughi, Wenke Lee

- **Temporal Working Memory: Query-Guided Temporal Segment Refinement for Enhanced Multimodal Understanding**  
  *Conference:* Findings of NAACL 2025 \
  *Authors:* {Chunhui Zhang*, Xingjian Diao*}, Weiyi Wu, Zhongyu Ouyang, Peijun Qing, Ming Cheng, Soroush Vosoughi, Jiang Gui

- **Working Memory Identifies Reasoning Limits in Language Models**  
  *Conference:* EMNLP 2024 \
  *Authors:* Chunhui Zhang, Yiren Jian, Zhongyu Ouyang, Soroush Vosoughi  



---

### ðŸ’¼ Internship Experience

#### **Honda Research Institute USA**  
*Research Intern (Jun. 2024 â€“ Sept. 2024)*  
- **Project:** Multimodal LLM Post-Training  
- Developed a **LLM-powered reasoner** capable of understanding human behaviors in **multimodal environments**, achieving a **4.6% improvement** over state-of-the-art solutions.  
- The paper is under review, and the code has been released.  
- **Host:** [Dr. Shao-Yuan Lo](https://shaoyuanlo.github.io/)  

---

### ðŸŒ± Current Focus

I am currently exploring **Multimodal LLMs** (Language-Vision-Audio), **memory mechanisms**, and **reinforcement learning** to push the boundaries of AGI. My recent work includes training recipes for large-scale models, which ranked **Top-2 on PaperWithCodeâ€™s Video Captioning Leaderboard**, showcasing optimal strategies for resource allocation in post-training.

---

### ðŸ“« Reach Me

- Email: [chunhui.zhang.gr@dartmouth.edu](mailto:chunhui.zhang.gr@dartmouth.edu)  
- LinkedIn: [Chunhui Zhang](https://www.linkedin.com/in/chunhui-zhang-541827161/)  
- GitHub: [chunhuizng](https://github.com/chunhuizng)  
- Google Scholar: [My Publications](https://scholar.google.com.hk/citations?user=im3dmssAAAAJ&hl=en)  

---

### ðŸ’¬ Let's Connect

Feel free to reach out if you're interested in collaboration, career advice, or just a friendly chat about research and life!  
